<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Lab 2 | Fast Robots</title>
  <link rel="stylesheet" href="../../style.css" />
  <!-- MathJax for LaTeX equations -->
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .topbar {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 12px;
      margin: 16px 0 10px;
    }

    .back-button {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border: 1px solid var(--border);
      background: rgba(255,255,255,0.04);
      color: var(--text);
      text-decoration: none;
      border-radius: 10px;
      font-size: 14px;
    }

    .back-button:hover { text-decoration: none; filter: brightness(1.05); }

    .muted { color: var(--muted); }

    .media {
      background: rgba(255,255,255,0.04);
      border: 1px dashed var(--border);
      border-radius: 12px;
      padding: 12px;
      margin: 10px 0 16px;
    }

    h2 {
      margin-top: 28px;
      padding-top: 10px;
      border-top: 1px solid var(--border);
    }

    .video-wrap {
      position: relative;
      width: 100%;
      padding-top: 56.25%;
      border-radius: 12px;
      overflow: hidden;
      border: 1px solid var(--border);
      background: #000;
      margin: 10px 0 16px;
    }

    .video-wrap iframe {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      border: 0;
    }

    .footer {
      margin-top: 26px;
      padding-top: 16px;
      border-top: 1px solid var(--border);
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 10px;
      font-size: 14px;
    }
    .img-small {
      max-width: 520px;
      width: 100%;
      height: auto;
      display: block;
      margin: 10px auto 6px;
      border-radius: 10px;
      border: 1px solid var(--border);
    }

    .img-medium {
      max-width: 800px;
      width: 100%;
      height: auto;
      display: block;
      margin: 10px auto 6px;
      border-radius: 10px;
      border: 1px solid var(--border);
    }
  </style>
</head>

<body>
  <div class="container">
    <div class="topbar">
      <!-- Adjust this path based on where you put lab1.html -->
      <a class="back-button" href="../../index.html">← Back to Main Page</a>
      <span class="muted">Fast Robots | Spring 2026</span>
    </div>

    <h1>Lab 2: IMU</h1>
   



    <div class="card">
      <h3>Objective</h3>
      <p>
        The goal of this lab was to acquire and analyze accelerometer and gyroscope data from a 9-DOF IMU on the Artemis board. Pitch, roll, and yaw were computed using sensor models from class, and low-pass and complementary filters were applied to improve robustness. IMU data was buffered onboard and transmitted over Bluetooth for offline analysis in Python.
      </p>
    </div>

    <div class="card">
      <h3>Setup</h3>
      <p>
        I first installed the ICM-20948 Arduino Library using the Arduino Library Manager. 
        The IMU was connected to the RedBoard Artemis Nano using the QWIIC connectors.
      </p>
      <img class="img-small" src="connection.png" alt="connection imu">
      <p>
        To verify the hardware connection and library setup, I ran the example sketch
from the SparkFun library. After uploading, the Serial Monitor can successfully print accelerometer, gyroscope, and magnetometer data.
      </p>


      <div class="video-wrap">
        <iframe src="https://www.youtube.com/embed/1i1zINzfdO0" allowfullscreen></iframe>
      </div>

      <h4>AD0_VAL Discussion</h4>
        <p>
            In the example code, the variable AD0_VAL specifies the least significant bit of the IMU’s I²C address.
            On the SparkFun breakout, the AD0 pin is pulled high by default, so AD0_VAL should be set to 1.

            
        </p>
      
      <h4>Accelerometer and Gyroscope Behavior</h4>
      <p>
        While I ran the example code, the accelerometer readings changed with board orientation. When the board was stationary and lying flat, one axis measured approximately ±1 g due to gravity while the other axes remained near zero, and tilting or flipping the board redistributed this gravity component across axes.
        And the gyroscope measured angular velocity, which means staying near zero when the board was still and producing clear spikes during rotation, with faster motion would cause a larger values before returning close to zero. 
      </p>




    </div>




    <div class="card">
      <h3>Tasks</h3>

      <div class="card">


      <h4>1. Accelerometer</h4>
      <p>
        In this section, I used accelerometer measurements to estimate board orientation and to understand the effects of noise on these measurements. 
        First, Pitch and roll were computed using the standard equations discussed in class, based on the gravity vector measured by the accelerometer.
        
      </p>

      <p>
        $$
         \theta_a = \operatorname{atan2}(a_x, a_z) 
        $$
      </p>
      
      <p>
        $$
         \phi_a = \operatorname{atan2}(a_y, a_z) 
        $$
      </p>

      <p>   
        In Arduino IDE, the accelerometer values were read in milligravity units and converted into pitch and roll angles as follows:
      </p>
      <pre><code class="language-cpp">float roll_rad  = atan2(ay, az);
float pitch_rad = atan2(-ax, sqrt(ay*ay + az*az));
float roll_deg  = roll_rad  * 180.0 / M_PI;
float pitch_deg = pitch_rad * 180.0 / M_PI;
</code></pre>

      <p>
        To validate the accelerometer-based orientation estimates, I rotated the IMU through known angles and recorded the output.
        Figures below show the roll and pitch angles as the board was positioned near −90°, 0°, and +90°.
      </p>
      <img class="img-medium" src="pandr.png" alt="pitch and roll">
      <p>  
        When the board was held flat, both pitch and roll remained near 0°. I rotated the board by approximately ±90° caused the corresponding angle to saturate near ±90°, 
        as expected from the geometry of the gravity vector. Small fluctuations near the extrema were due to sensor noise and slight hand motion during the test.
      </p>

    
      <p>
        A short video was also recorded showing the physical motion of the board alongside the serial output to confirm that the reported angles tracked the motion in real time.
      </p>

      <div class="video-wrap">
        <iframe src="https://www.youtube.com/embed/nd0B1BVTZLU" allowfullscreen></iframe>
      </div>
      <p>

        From the collected accelerometer data and the pitch and roll plots, I evaluated the accuracy of the angle estimates at approximately ±90°. For each orientation, 
        the measured angles closely matched the expected values, with the readings typically fluctuating within about 1–2 degrees. Across all tested orientations, the accelerometer provided reliable pitch and roll estimates under static conditions. A two-point calibration was not necessary for this part of the lab.
      </p>

      <p>
        
        To analyze noise in the accelerometer data, I examined the z-axis acceleration (az) recorded while manually rotating and holding the IMU. 
      </p>
      <img class="img-small" src="az.png" alt="az">

      <p>
        The figure above shows the time-domain az signal. While the gravity component dominates when the IMU is held steady, the signal contains sharp transients and noticeable high-frequency jitter during orientation changes. These effects are especially visible around the transition regions, where spikes and oscillations appear before the signal settles.
        Small fluctuations remain even after the IMU becomes stationary. This behavior motivates further analysis in the frequency domain.
      </p>

      <p>   
        To understand the frequency content of the noise, I computed the Fast Fourier Transform (FFT) of the entire az signal using Python. 

      </p>

      <p>   
        The discrete Fourier transform is defined as:
      </p>

      <p>
      $$
      X(f_k) = \sum_{n=0}^{N-1} x[n] e^{-j 2 \pi k n / N}
      $$
      </p>

      <p>
        where x[n] is the sampled signal and N is the total number of samples.
      </p>

      <img class="img-small" src="fft.png" alt="eq2">

      <p>
        The figure above shows the FFT amplitude spectrum of az. Most of the signal energy is concentrated below approximately 1–2 Hz, showing that slow orientation changes.
        Above this range, the spectrum flattens and contains lower-amplitude components associated with noise and vibration.
        So, a cutoff frequency of approximately 2 Hz was chosen. 
      </p>

      <p>

        Using the cutoff frequency from the FFT, I applied a first-order RC low-pass filter to the filtered az computed from the accelerometer equations. The RC relationship from lecture is:
      </p>

      <p>
        $$
        RC = \frac{1}{2\pi f_c}
        $$
      </p>
      
      <p>
        and the discrete-time low-pass filter update is:
      </p>
      
      <p>
        $$
        \alpha = \frac{\Delta t}{RC + \Delta t},
        \qquad
        y[k] = \alpha x[k] + (1-\alpha)\,y[k-1]
        $$
      </p>
      <p>
        This is implemented directly in my Arduino code as:
      </p>

      <pre><code class="language-cpp">float tau = 1.0 / (2 * M_PI * fc);
float alpha = dt / (tau + dt);
az_filt = alpha * az + (1 - alpha) * az_filt;
</code></pre>

      <img class="img-small" src="og vs lpf.png" alt="eq2">

      <p>
        The low-pass filter smooths the signal and removes high-frequency jitter and spikes, but it adds a small lag during rapid changes. Overall the filtered output is more stable and better suited for sensor fusion.
      </p>
    </div>

    <div class="card">

        <h4>2. Gyroscope</h4>

        <p>
        In this section, I computed orientation angles using the gyroscope, compare them with accelerometer-based estimates, and show how a complementary filter improves accuracy and stability.
        </p>
        <p>
        I first integrated the gyro angular rates over time using the discrete-time update from lecture to estimate orientation from the gyroscope::
        </p>
        <p>
        $$
        \theta[k] = \theta[k-1] + \omega[k]\Delta t
        $$
        </p>
        <p>
            Because the gyroscope measures angular velocity, small biases accumulate over time, leading to drift in the estimated angles.
            The gyroscope-based pitch was compared with raw accelerometer pitch and low-pass filtered accelerometer pitch at both 30 Hz and 10 Hz.
        </p>
        <img class="img-small" src="pitch10.png" alt="eq2">
        <img class="img-small" src="pitch30.png" alt="eq2">
        <p>
            In the pitch plots, the raw accelerometer estimate is noisy and contains spikes during motion, while the filtered accelerometer estimate is smoother but slightly lags during rapid transitions. The gyroscope pitch is smooth and responds quickly, but it gradually drifts away from the accelerometer-based estimates, particularly after motion ends.
        </p>
        <p>

            <img class="img-small" src="roll10.png" alt="eq2">
            <img class="img-small" src="roll30.png" alt="eq2">
        </p>
        <p>
            A similar trend is observed in the roll plots. The raw accelerometer roll shows large spikes and instability, the filtered accelerometer roll significantly reduces this noise, and the gyroscope roll remains smooth but exhibits offset and drift over time.
            Comparing sampling frequencies, the 30 Hz results track motion more accurately and return closer to the original baseline after movement. At 10 Hz, both pitch and roll show increased drift and reduced accuracy, indicating that lower sampling frequency amplifies integration error and degrades gyroscope based angle estimation.

        </p>

        <p>
            The complementary filter blends the high frequency response of the gyroscope with the low frequency stability of the accelerometer. 
            Then I implemented a complementary filter to estimate pitch and roll using the equations from lecture, the filter is defined as:
        </p>

        <p>
            $$
            \theta_{cf}[k] = \alpha \big( \theta_{cf}[k-1] + \omega[k]\Delta t \big) + (1-\alpha)\theta_a[k]
            $$
        </p>


        <p>
        The complementary filter was implemented in the main loop for both pitch and roll:


        </p>

        <pre><code class="language-cpp">// Complementary filter parameters
float fc = 2.0;                 // cutoff frequency (Hz)
float tau = 1.0 / (2.0 * M_PI * fc);
float alpha = tau / (tau + dt); 
// Gyro integration
pitch_g = pitch_g + gyro_y * dt;
roll_g  = roll_g  + gyro_x * dt;
// Complementary filter
pitch_cf = alpha * pitch_g + (1 - alpha) * pitch_acc;
roll_cf  = alpha * roll_g  + (1 - alpha) * roll_acc;
</code></pre>

        <img class="img-small" src="pitchco.png" alt="eq2">
        <img class="img-small" src="rollco.png" alt="eq2">
        <p>
            The figure above compare the orientation estimates from the accelerometer, filtered accelerometer, gyroscope, and complementary filter.
        </p>
        <p>
            we can see the complementary filter tracks fast motion like the gyroscope but stays stable over time without drift. Compared to raw accelerometer estimates,
            it also reduces vibration noise while keeping accurate angles across the full range.
        </p>


    
    </div>

    <div class="card">
        <h4>3. Sample Data</h4>
        <p>
            In this session, I followed the Lab 1 framework and moved all high-rate data collection onto the Artemis to avoid delays from continuous BLE transmission.
            First, I restructured the main loop to run as fast as possible by removing all delay() calls and commenting out most Serial.print() statements.

        </p>
        <p>
            Rather than waiting for IMU data in a blocking way, I checked myICM.dataReady() on every loop iteration and immediately stored the data when it became available.
             Each IMU sample was saved along with a microsecond-resolution timestamp:                   
        </p>
        <pre><code class="language-cpp">if (imu_recording && myICM.dataReady()) {
    myICM.getAGMT();
    imu_buf[imu_count].t_us = micros();
    imu_buf[imu_count].ax = myICM.agmt.acc.axes.x;
    imu_buf[imu_count].ay = myICM.agmt.acc.axes.y;
    imu_buf[imu_count].az = myICM.agmt.acc.axes.z;
    imu_buf[imu_count].gx = myICM.agmt.gyr.axes.x;
    imu_buf[imu_count].gy = myICM.agmt.gyr.axes.y;
    imu_buf[imu_count].gz = myICM.agmt.gyr.axes.z;
    imu_count++;
    }  </code></pre>

        <p>
            I used a flag-based approach to control recording. Recording started when a BLE command was received and automatically stopped after 5 seconds or when the buffer filled:
        </p>
        <pre><code class="language-cpp">if (micros() - imu_start_us > 5000000UL) {
    imu_recording = false;
}   
        </code></pre>




        <p>
            This ensured the main loop continued running freely and was not limited by IMU or BLE timing. Then I stored IMU data using a single struct-based array:
        </p>

        <pre><code class="language-cpp">struct ImuSample {
    uint32_t t_us;
    int16_t ax, ay, az;
    int16_t gx, gy, gz;
    };</code></pre>

        <p>
            I chose a single array rather than separate accelerometer and gyroscope arrays to keep all measurements time-aligned and simplify data handling. I stored raw int16_t sensor values instead of floats to reduce memory usage and minimize BLE transmission overhead.
        </p>

        <p>
            On the Python side, I reused the BLE command and notification framework from Lab 1. I started recording by sending a RECORD_IMU_DATA command and then requested the buffered data using SEND_IMU_DATA.
            Then I used a notification handler to parse each incoming IMU packet and append it to a Python list for offline processing:

        </p>
        <pre><code class="language-python">def imu_handler(uuid, byte_array):
    msg = ble.bytearray_to_string(byte_array).strip()
    if msg.startswith("I:"):
        vals = msg[2:].split(",")
        imu_dump.append(tuple(int(v) for v in vals))</code></pre>
        <p>
            Using this approach, I successfully recorded and transmitted a full 5 seconds of IMU data over Bluetooth:
        </p>
        <img class="img-small" src="5spy.png" alt="eq2">   
        <p>
            This corresponds to an effective sampling rate of approximately 337 Hz, showing that the main loop runs faster than the IMU produces new data. The recorded accelerometer values remained stable when the board was stationary, confirming correct timing and buffering.
        </p>  
        <img class="img-small" src="5s.png" alt="eq2">   
        <p>
            This figure demonstrates continuous sampling, correct timestamps, and successful data buffering.

        </p> 

    </div>

    <div class="card">

        <h4>4. RC car stunt</h4>


        <div class="video-wrap">
            <iframe src="https://www.youtube.com/embed/8ndCtBMi-mU" allowfullscreen></iframe>
          </div>

        <p>
            For the stunt, I drove the RC car and performed couple flips.  The car felt fast and had a lot of torque, which made it responsive but also easy to tip over. 
        </p>


        </div>




    <div class="card">
      <h3>Conclusion</h3>
      <p>
        In this lab, I used the Artemis IMU to estimate orientation and see how real sensor data behaves. I used FFT and filtering to deal with noise, and a complementary filter to reduce drift while keeping fast response. I also logged 5 seconds of IMU data onboard and sent it over BLE for analysis. Overall, this lab made IMU sensing feel a lot more practical, and I’m ready to use it in later labs.

      </p>
        
        
                
    </div>

    <div class="footer">
      <a class="back-button" href="../../index.html">← Back to Main Page</a>
    </div>
  </div>
</body>
</html>